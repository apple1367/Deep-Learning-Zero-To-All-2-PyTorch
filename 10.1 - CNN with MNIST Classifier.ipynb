{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lab 10.1: CNN with MNIST Classifier\r\n",
    "\r\n",
    "Edited By Steve Ive\r\n",
    "\r\n",
    "Here, we are going to build simple CNN model for MNIST Classifying. To more understand about CNN, please refer before script \"10.0 - About CNN\".\r\n",
    "\r\n",
    "Reference from\r\n",
    "\r\n",
    "https://github.com/deeplearningzerotoall/PyTorch/blob/master/lab-10_1_mnist_cnn.ipynb"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "import torch.nn.init as init\r\n",
    "import torchvision.datasets as datasets\r\n",
    "import torchvision.transforms as transforms"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "\r\n",
    "torch.manual_seed(1)\r\n",
    "\r\n",
    "if device == 'cuda':\r\n",
    "    torch.cuda.manual_seed(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load MNIST Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "mnist_train = datasets.MNIST(root = 'MNIST_data/',\r\n",
    "                             download = True,\r\n",
    "                             train = True,\r\n",
    "                             transform = transforms.ToTensor())\r\n",
    "mnist_test = datasets.MNIST(root = 'MNIST_data/',\r\n",
    "                            download = True,\r\n",
    "                            train = False,\r\n",
    "                            transform = transforms.ToTensor())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset = mnist_train, batch_size = batch_size, shuffle = True, drop_last = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set Hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "batch_size = 100\r\n",
    "training_epochs = 20\r\n",
    "learning_rate = 0.001"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "class MNIST_CNN(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        # Layer 1: ImageInput Shape=(?, 28, 28, 1)\r\n",
    "        # Conv   : ImageOutput Shape=(?, 28, 28, 32)\r\n",
    "        # Pool   : ImageOutput Shape=(?, 14, 14, 32)\r\n",
    "        self.layer1 = nn.Sequential(\r\n",
    "            nn.Conv2d(1, 32, kernel_size = 3, stride = 1, padding = 1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\r\n",
    "        )\r\n",
    "        # Layer 2: ImageInput Shape=(?, 14, 14, 32)\r\n",
    "        # Conv   : ImageOutput Shape=(?, 14, 14, 64)\r\n",
    "        # Pool   : ImageOutput Shape=(?, 7, 7, 64)\r\n",
    "        self.layer2 = nn.Sequential(\r\n",
    "            nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\r\n",
    "        )\r\n",
    "        # Final Fully Connected\r\n",
    "        # 7 x 7 x 64 inputs => 10 outputs\r\n",
    "        self.fc = nn.Linear(7 * 7 * 64, 10)\r\n",
    "        init.xavier_uniform_(self.fc.weight)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = self.layer1(x)\r\n",
    "        out = self.layer2(out)\r\n",
    "        #print(out.size()) #torch.size([100, 64, 7, 7])\r\n",
    "        out = out.view(out.size(0), -1) # Flatten for FC\r\n",
    "        out = self.fc(out)\r\n",
    "        return out    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "model = MNIST_CNN().to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "total_batch = len(data_loader)\r\n",
    "\r\n",
    "print('Learning started')\r\n",
    "\r\n",
    "for epoch in range(training_epochs):\r\n",
    "\r\n",
    "    avg_cost = 0\r\n",
    "\r\n",
    "    for X, Y in data_loader:\r\n",
    "        # image is already size of (28 x 28), no reshape\r\n",
    "        # Label is not one-hot encoded\r\n",
    "\r\n",
    "        X = X.to(device)\r\n",
    "        Y = Y.to(device)\r\n",
    "\r\n",
    "        #prediction\r\n",
    "        pred = model(X)\r\n",
    "\r\n",
    "        #cost\r\n",
    "        cost = F.cross_entropy(pred, Y).to(device)\r\n",
    "\r\n",
    "        #Reduce the cost\r\n",
    "        optimizer.zero_grad()\r\n",
    "        cost.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        avg_cost += cost\r\n",
    "\r\n",
    "    avg_cost = avg_cost / total_batch\r\n",
    "\r\n",
    "    print('Epoch: {} / {}, cost: {:.6f}'.format(epoch + 1, training_epochs, avg_cost))\r\n",
    "print('Learning Finished')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learning started\n",
      "Epoch: 1 / 20, cost: 0.218914\n",
      "Epoch: 2 / 20, cost: 0.059701\n",
      "Epoch: 3 / 20, cost: 0.044733\n",
      "Epoch: 4 / 20, cost: 0.034433\n",
      "Epoch: 5 / 20, cost: 0.029811\n",
      "Epoch: 6 / 20, cost: 0.024734\n",
      "Epoch: 7 / 20, cost: 0.020639\n",
      "Epoch: 8 / 20, cost: 0.017615\n",
      "Epoch: 9 / 20, cost: 0.015055\n",
      "Epoch: 10 / 20, cost: 0.012490\n",
      "Epoch: 11 / 20, cost: 0.010240\n",
      "Epoch: 12 / 20, cost: 0.009451\n",
      "Epoch: 13 / 20, cost: 0.007774\n",
      "Epoch: 14 / 20, cost: 0.007936\n",
      "Epoch: 15 / 20, cost: 0.005897\n",
      "Epoch: 16 / 20, cost: 0.005412\n",
      "Epoch: 17 / 20, cost: 0.003761\n",
      "Epoch: 18 / 20, cost: 0.005102\n",
      "Epoch: 19 / 20, cost: 0.004148\n",
      "Epoch: 20 / 20, cost: 0.003553\n",
      "Learning Finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Take a Moment!\r\n",
    "\r\n",
    "Why we should ```.view(len(mnist_test), 1, 28 ,28)``` below despite of we didn't do that upon?\r\n",
    "\r\n",
    "=> since ```data_loader``` makes mini batches as size of size([100, 1, 28, 28]), we don't have to do that manually, but we don't use ```data_loader``` below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "#Test model and check accuracy\r\n",
    "with torch.no_grad():\r\n",
    "    #print(mnist_test.data.shape) => torch.Size([10000, 28, 28])\r\n",
    "    X_test = mnist_test.data.view(len(mnist_test), 1, 28, 28).float().to(device)\r\n",
    "    Y_test = mnist_test.targets.to(device)\r\n",
    "\r\n",
    "    #prediction\r\n",
    "    pred = model(X_test)\r\n",
    "    correct_prediction = (torch.argmax(pred, 1) == Y_test)\r\n",
    "    accuracy = correct_prediction.float().mean()\r\n",
    "\r\n",
    "    print('Accuracy: ', accuracy.item())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  0.9829999804496765\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('buddhalight': conda)"
  },
  "interpreter": {
   "hash": "38ed4d61829b01de31b0fe0651719916120d9f7e023a62cbbfea93b7d24a50a0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}