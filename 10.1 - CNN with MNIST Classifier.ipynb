{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lab 10.1: CNN with MNIST Classifier\r\n",
    "\r\n",
    "Edited By Steve Ive\r\n",
    "\r\n",
    "Here, we are going to build simple CNN model for MNIST Classifying. To more understand about CNN, please refer before script \"10.0 - About CNN\".\r\n",
    "\r\n",
    "Reference from\r\n",
    "\r\n",
    "https://github.com/deeplearningzerotoall/PyTorch/blob/master/lab-10_1_mnist_cnn.ipynb"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "import torch.nn.init as init\r\n",
    "import torchvision.datasets as datasets\r\n",
    "import torchvision.transforms as transforms"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "\r\n",
    "torch.manual_seed(1)\r\n",
    "\r\n",
    "if device == 'cuda':\r\n",
    "    torch.cuda.manual_seed(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "mnist_train = datasets.MNIST(root = 'MNIST_data/',\r\n",
    "                             download = True,\r\n",
    "                             train = True,\r\n",
    "                             transform = transforms.ToTensor())\r\n",
    "mnist_test = datasets.MNIST(root = 'MNIST_data/',\r\n",
    "                            download = True,\r\n",
    "                            train = False,\r\n",
    "                            transform = transforms.ToTensor())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "batch_size = 100\r\n",
    "training_epochs = 20\r\n",
    "learning_rate = 0.001"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset = mnist_train, batch_size = batch_size, shuffle = True, drop_last = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class MNIST_CNN(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        # Layer 1: ImageInput Shape=(?, 28, 28, 1)\r\n",
    "        # Conv   : ImageInput Shape=(?, 28, 28, 32)\r\n",
    "        # Pool   : ImageInput Shape=(?, 14, 14, 32)\r\n",
    "        self.layer1 = nn.Sequential(\r\n",
    "            nn.Conv2d(1, 32, kernel_size = 3, stride = 1, padding = 1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\r\n",
    "        )\r\n",
    "        # Layer 2: ImageInput Shape=(?, 14, 14, 32)\r\n",
    "        # Conv   : ImageInput Shape=(?, 14, 14, 64)\r\n",
    "        # Pool   : ImageInput Shape=(?, 7, 7, 64)\r\n",
    "        self.layer2 = nn.Sequential(\r\n",
    "            nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\r\n",
    "        )\r\n",
    "        # Final Fully Connected\r\n",
    "        # 7 x 7 x 64 inputs => 10 outputs\r\n",
    "        self.fc = nn.Linear(7 * 7 * 64, 10)\r\n",
    "        init.xavier_uniform_(self.fc.weight)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = self.layer1(x)\r\n",
    "        out = self.layer2(out)\r\n",
    "        #print(out.size()) #torch.size([100, 64, 7, 7])\r\n",
    "        out = out.view(out.size(0), -1) # Flatten for FC\r\n",
    "        out = self.fc(out)\r\n",
    "        return out    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model = MNIST_CNN().to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "total_batch = len(data_loader)\r\n",
    "\r\n",
    "print('Learning started')\r\n",
    "\r\n",
    "for epoch in range(training_epochs):\r\n",
    "\r\n",
    "    avg_cost = 0\r\n",
    "\r\n",
    "    for X, Y in data_loader:\r\n",
    "        # image is already size of (28 x 28), no reshape\r\n",
    "        # Label is not one-hot encoded\r\n",
    "\r\n",
    "        X = X.to(device)\r\n",
    "        Y = Y.to(device)\r\n",
    "\r\n",
    "        #prediction\r\n",
    "        pred = model(X)\r\n",
    "\r\n",
    "        #cost\r\n",
    "        cost = F.cross_entropy(pred, Y).to(device)\r\n",
    "\r\n",
    "        #Reduce the cost\r\n",
    "        optimizer.zero_grad()\r\n",
    "        cost.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        avg_cost += cost\r\n",
    "\r\n",
    "    avg_cost = avg_cost / total_batch\r\n",
    "\r\n",
    "    print('Epoch: {} / {}, cost: {:.6f}'.format(epoch + 1, training_epochs, avg_cost))\r\n",
    "print('Learning Finished')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Learning started\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1 / 20, cost: 0.218919\n",
      "Epoch: 2 / 20, cost: 0.059666\n",
      "Epoch: 3 / 20, cost: 0.044729\n",
      "Epoch: 4 / 20, cost: 0.034445\n",
      "Epoch: 5 / 20, cost: 0.029801\n",
      "Epoch: 6 / 20, cost: 0.024727\n",
      "Epoch: 7 / 20, cost: 0.020556\n",
      "Epoch: 8 / 20, cost: 0.017596\n",
      "Epoch: 9 / 20, cost: 0.014956\n",
      "Epoch: 10 / 20, cost: 0.012632\n",
      "Epoch: 11 / 20, cost: 0.009928\n",
      "Epoch: 12 / 20, cost: 0.009620\n",
      "Epoch: 13 / 20, cost: 0.007476\n",
      "Epoch: 14 / 20, cost: 0.007555\n",
      "Epoch: 15 / 20, cost: 0.006531\n",
      "Epoch: 16 / 20, cost: 0.005704\n",
      "Epoch: 17 / 20, cost: 0.003859\n",
      "Epoch: 18 / 20, cost: 0.003481\n",
      "Epoch: 19 / 20, cost: 0.004580\n",
      "Epoch: 20 / 20, cost: 0.004117\n",
      "Learning Finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Take a Moment!\r\n",
    "\r\n",
    "Why we should ```.view(len(mnist_test), 1, 28 ,28)``` below despite of we didn't do that upon?\r\n",
    "\r\n",
    "=> since ```data_loader``` makes mini batches as size of size([100, 1, 28, 28]), we don't have to do that manually, but we don't use ```data_loader``` below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#Test model and check accuracy\r\n",
    "with torch.no_grad():\r\n",
    "    #print(mnist_test.data.shape) => torch.Size([10000, 28, 28])\r\n",
    "    X_test = mnist_test.data.view(len(mnist_test), 1, 28, 28).float().to(device)\r\n",
    "    Y_test = mnist_test.targets.to(device)\r\n",
    "\r\n",
    "    #prediction\r\n",
    "    pred = model(X_test)\r\n",
    "    correct_prediction = (torch.argmax(pred, 1) == Y_test)\r\n",
    "    accuracy = correct_prediction.float().mean()\r\n",
    "\r\n",
    "    print('Accuracy: ', accuracy.item())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  0.9842999577522278\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('buddhalight': conda)"
  },
  "interpreter": {
   "hash": "38ed4d61829b01de31b0fe0651719916120d9f7e023a62cbbfea93b7d24a50a0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}