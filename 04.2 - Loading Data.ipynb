{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('deep-learning': conda)"
  },
  "interpreter": {
   "hash": "37cc7290eaadfd237ba9edfee5f5646f2226d20dfbf33e67928708333f7a6cd3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Lab 4.2: Load Data\n",
    "\n",
    "Edited By Steve Ive\n",
    "\n",
    "Reference from Seungjae Lee\n",
    "\n",
    "https://github.com/deeplearningzerotoall/PyTorch/blob/master/lab-04_2_load_data.ipynb"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Slicing 1D Array"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(nums)"
   ]
  },
  {
   "source": [
    "contain index 2 before 4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(nums[2:4])"
   ]
  },
  {
   "source": [
    "bring all from index 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(nums[2:])"
   ]
  },
  {
   "source": [
    "bring all before index 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(nums[:2])"
   ]
  },
  {
   "source": [
    "bring all"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(nums[:])"
   ]
  },
  {
   "source": [
    "bring all before the last index"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(nums[:-1])"
   ]
  },
  {
   "source": [
    "We can assign too!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums[2:4] = [8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 8, 9, 4]\n"
     ]
    }
   ],
   "source": [
    "print(nums)"
   ]
  },
  {
   "source": [
    "## Slicing 2D Array"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 2,  6, 10])"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "b[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 9, 10, 11, 12])"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "b[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 9, 10, 11, 12])"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "b[-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 9, 10, 11, 12])"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "b[-1, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [5, 6, 7, 8]])"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "b[0:2, :]"
   ]
  },
  {
   "source": [
    "## Loading Data from .csv file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data-01-test-score.csv', delimiter=',', dtype=np.float32)"
   ]
  },
  {
   "source": [
    "### Take a Moment!\n",
    "\n",
    "```y_data = xy[:, [-1]]```\n",
    "\n",
    "brings the all rows of last column with [] array wrapped"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = xy[:, 0: -1]\n",
    "y_data = xy[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(25, 3)\n25\n[[ 73.  80.  75.]\n [ 93.  88.  93.]\n [ 89.  91.  90.]\n [ 96.  98. 100.]\n [ 73.  66.  70.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape)\n",
    "print(len(x_data))\n",
    "print(x_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(25, 1)\n25\n[[152.]\n [185.]\n [180.]\n [196.]\n [142.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_data.shape)\n",
    "print(len(y_data))\n",
    "print(y_data[:5])"
   ]
  },
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25d84c6ffd0>"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "source": [
    "## Low-level Implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    0/20 Hypotheis: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0.]) Cost: 26811.960938\nEpoch    1/20 Hypotheis: tensor([60.3300, 72.5121, 71.4468, 77.8114, 55.3021, 40.7728, 58.2450, 43.1799,\n        67.7685, 62.7711, 56.1159, 55.3320, 73.8140, 61.3605, 58.5129, 73.5830,\n        58.4375, 69.8998, 70.3709, 62.9651, 68.3015, 68.0264, 65.1199, 60.8261,\n        75.1500]) Cost: 9920.530273\nEpoch    2/20 Hypotheis: tensor([ 97.0136, 116.6032, 114.8901, 125.1249,  88.9286,  65.5651,  93.6612,\n         69.4359, 108.9755, 100.9401,  90.2373,  88.9771, 118.6964,  98.6703,\n         94.0921, 118.3256,  93.9699, 112.4028, 113.1596, 101.2509, 109.8326,\n        109.3903, 104.7163,  97.8108, 120.8450]) Cost: 3675.298828\nEpoch    3/20 Hypotheis: tensor([119.3189, 143.4130, 141.3056, 153.8940, 109.3752,  80.6404, 115.1964,\n         85.4014, 134.0320, 124.1496, 110.9851, 109.4354, 145.9869, 121.3560,\n        115.7265, 145.5315, 115.5747, 138.2472, 139.1770, 124.5302, 135.0859,\n        134.5418, 128.7932, 120.2987, 148.6299]) Cost: 1366.260986\nEpoch    4/20 Hypotheis: tensor([132.8815, 159.7147, 157.3676, 171.3871, 121.8078,  89.8073, 128.2911,\n         95.1098, 149.2679, 138.2630, 123.6010, 121.8754, 162.5806, 135.1496,\n        128.8816, 162.0744, 128.7110, 153.9623, 154.9965, 138.6849, 150.4415,\n        149.8355, 143.4333, 133.9718, 165.5244]) Cost: 512.542297\nEpoch    5/20 Hypotheis: tensor([141.1279, 169.6271, 167.1339, 182.0239, 129.3674,  95.3815, 136.2537,\n        101.0134, 158.5325, 146.8454, 131.2722, 129.4399, 172.6700, 143.5362,\n        136.8809, 172.1335, 136.6978, 163.5182, 164.6151, 147.2913, 159.7788,\n        159.1350, 152.3354, 142.2851, 175.7970]) Cost: 196.896500\nEpoch    6/20 Hypotheis: tensor([146.1420, 175.6543, 173.0722, 188.4916, 133.9639,  98.7712, 141.0955,\n        104.6036, 164.1662, 152.0648, 135.9367, 134.0399, 178.8046, 148.6351,\n        141.7451, 178.2501, 141.5535, 169.3291, 170.4633, 152.5240, 165.4566,\n        164.7898, 157.7485, 147.3392, 182.0432]) Cost: 80.190903\nEpoch    7/20 Hypotheis: tensor([149.1906, 179.3192, 176.6828, 192.4244, 136.7588, 100.8327, 144.0398,\n        106.7870, 167.5922, 155.2392, 138.7732, 136.8372, 182.5343, 151.7350,\n        144.7032, 181.9696, 144.5053, 172.8627, 174.0189, 155.7055, 168.9092,\n        168.2285, 161.0401, 150.4117, 185.8411]) Cost: 37.038647\nEpoch    8/20 Hypotheis: tensor([151.0440, 181.5477, 178.8781, 194.8158, 138.4581, 102.0864, 145.8304,\n        108.1151, 169.6756, 157.1702, 140.4980, 138.5385, 184.8019, 153.6193,\n        146.5022, 184.2314, 146.2995, 175.0116, 176.1805, 157.6395, 171.0088,\n        170.3195, 163.0418, 152.2793, 188.1503]) Cost: 21.081354\nEpoch    9/20 Hypotheis: tensor([152.1707, 182.9027, 180.2128, 196.2698, 139.4913, 102.8490, 146.9194,\n        108.9232, 170.9428, 158.3452, 141.5469, 139.5733, 186.1803, 154.7645,\n        147.5963, 185.6068, 147.3897, 176.3186, 177.4944, 158.8152, 172.2858,\n        171.5912, 164.2590, 153.4141, 189.5543]) Cost: 15.178741\nEpoch   10/20 Hypotheis: tensor([152.8556, 183.7267, 181.0242, 197.1540, 140.1195, 103.3131, 147.5817,\n        109.4149, 171.7137, 159.0604, 142.1848, 140.2028, 187.0181, 155.4602,\n        148.2619, 186.4433, 148.0520, 177.1137, 178.2929, 159.5296, 173.0624,\n        172.3646, 164.9993, 154.1034, 190.4078]) Cost: 12.993667\nEpoch   11/20 Hypotheis: tensor([153.2718, 184.2277, 181.5174, 197.6917, 140.5014, 103.5955, 147.9847,\n        109.7144, 172.1828, 159.4961, 142.5727, 140.5859, 187.5271, 155.8827,\n        148.6669, 186.9522, 148.4540, 177.5975, 178.7780, 159.9637, 173.5349,\n        172.8351, 165.4496, 154.5218, 190.9267]) Cost: 12.183028\nEpoch   12/20 Hypotheis: tensor([153.5246, 184.5324, 181.8171, 198.0186, 140.7336, 103.7675, 148.2300,\n        109.8970, 172.4683, 159.7618, 142.8088, 140.8192, 187.8363, 156.1390,\n        148.9135, 187.2618, 148.6977, 177.8920, 179.0725, 160.2272, 173.8225,\n        173.1214, 165.7235, 154.7755, 191.2421]) Cost: 11.880545\nEpoch   13/20 Hypotheis: tensor([153.6781, 184.7177, 181.9992, 198.2175, 140.8746, 103.8724, 148.3794,\n        110.0084, 172.6423, 159.9241, 142.9524, 140.9613, 188.0239, 156.2943,\n        149.0637, 187.4502, 148.8453, 178.0714, 179.2512, 160.3871, 173.9976,\n        173.2956, 165.8902, 154.9291, 191.4338]) Cost: 11.765953\nEpoch   14/20 Hypotheis: tensor([153.7712, 184.8304, 182.1098, 198.3384, 140.9604, 103.9365, 148.4704,\n        110.0766, 172.7484, 160.0236, 143.0398, 141.0481, 188.1376, 156.3882,\n        149.1554, 187.5650, 148.9343, 178.1808, 179.3594, 160.4839, 174.1043,\n        173.4018, 165.9918, 155.0218, 191.5502]) Cost: 11.720860\nEpoch   15/20 Hypotheis: tensor([153.8275, 184.8989, 182.1769, 198.4120, 141.0124, 103.9758, 148.5260,\n        110.1186, 172.8133, 160.0849, 143.0931, 141.1012, 188.2064, 156.4447,\n        149.2114, 187.6349, 148.9877, 178.2476, 179.4248, 160.5424, 174.1694,\n        173.4665, 166.0536, 155.0774, 191.6208]) Cost: 11.701425\nEpoch   16/20 Hypotheis: tensor([153.8615, 184.9406, 182.2175, 198.4567, 141.0440, 103.9999, 148.5600,\n        110.1445, 172.8530, 160.1229, 143.1256, 141.1338, 188.2479, 156.4785,\n        149.2458, 187.6777, 149.0195, 178.2886, 179.4641, 160.5776, 174.2093,\n        173.5061, 166.0914, 155.1105, 191.6637]) Cost: 11.691506\nEpoch   17/20 Hypotheis: tensor([153.8820, 184.9660, 182.2421, 198.4840, 141.0631, 104.0149, 148.5810,\n        110.1608, 172.8776, 160.1469, 143.1455, 141.1539, 188.2727, 156.4985,\n        149.2670, 187.7038, 149.0382, 178.3138, 179.4876, 160.5986, 174.2337,\n        173.5303, 166.1145, 155.1299, 191.6896]) Cost: 11.685120\nEpoch   18/20 Hypotheis: tensor([153.8941, 184.9814, 182.2568, 198.5006, 141.0747, 104.0243, 148.5939,\n        110.1711, 172.8928, 160.1622, 143.1577, 141.1665, 188.2875, 156.5100,\n        149.2802, 187.7199, 149.0488, 178.3295, 179.5014, 160.6110, 174.2489,\n        173.5453, 166.1287, 155.1410, 191.7052]) Cost: 11.680006\nEpoch   19/20 Hypotheis: tensor([153.9013, 184.9908, 182.2656, 198.5107, 141.0816, 104.0303, 148.6020,\n        110.1778, 172.9024, 160.1723, 143.1652, 141.1745, 188.2961, 156.5165,\n        149.2885, 187.7299, 149.0546, 178.3394, 179.5094, 160.6182, 174.2583,\n        173.5546, 166.1375, 155.1470, 191.7146]) Cost: 11.675381\nEpoch   20/20 Hypotheis: tensor([153.9054, 184.9966, 182.2708, 198.5169, 141.0858, 104.0343, 148.6072,\n        110.1824, 172.9086, 160.1792, 143.1699, 141.1797, 188.3009, 156.5199,\n        149.2939, 187.7361, 149.0575, 178.3457, 179.5139, 160.6222, 174.2643,\n        173.5604, 166.1430, 155.1500, 191.7202]) Cost: 11.670943\n"
     ]
    }
   ],
   "source": [
    "#Data\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)\n",
    "\n",
    "#Model Initialize\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "#Set optimizer\n",
    "optimizer = optim.SGD([W, b], lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    #Hypothesis\n",
    "    pred = x_train.matmul(W) + b\n",
    "\n",
    "    #Cost\n",
    "    cost = torch.mean((pred - y_train)**2)\n",
    "\n",
    "    #Reduce cost\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {:4d}/{} Hypotheis: {} Cost: {:.6f}'.format(epoch, nb_epochs, pred.squeeze().detach(), cost.item()))"
   ]
  },
  {
   "source": [
    "## High-level Implementaion with ```nn.Module```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    0/20 Hypothesis: tensor([-6.7933, -4.8968, -6.5155, -7.3361, -2.6660, -1.8403, -6.6781, -6.7331,\n        -4.0525, -3.9151, -5.2111, -3.7514, -6.4568, -4.7845, -6.2377, -5.4874,\n        -3.2482, -8.9763, -6.6201, -6.2942, -7.3238, -5.0026, -7.1896, -6.2176,\n        -5.5024]) Cost: 28693.490234\nEpoch    1/20 Hypothesis: tensor([55.6147, 70.1117, 67.3916, 73.1548, 54.5398, 40.3360, 53.5729, 37.9342,\n        66.0489, 61.0169, 52.8371, 53.4856, 69.8990, 58.6889, 54.2903, 70.6290,\n        57.2013, 63.3310, 66.1742, 58.8394, 63.3299, 65.3660, 60.1730, 56.7034,\n        72.2351]) Cost: 10618.750000\nEpoch    2/20 Hypothesis: tensor([ 93.5619, 115.7207, 112.3309, 122.0975,  89.3237,  65.9814,  90.2090,\n         65.0951, 108.6743, 100.4994,  88.1336,  88.2888, 116.3270,  97.2834,\n         91.0948, 116.9119,  93.9569, 107.2983, 110.4365,  98.4438, 106.2914,\n        108.1538, 101.1332,  94.9621, 119.5033]) Cost: 3936.015381\nEpoch    3/20 Hypothesis: tensor([116.6357, 143.4532, 139.6562, 151.8574, 110.4738,  81.5753, 112.4861,\n         81.6110, 134.5929, 124.5075, 109.5959, 109.4512, 144.5573, 120.7503,\n        113.4743, 145.0544, 116.3054, 134.0332, 137.3500, 122.5251, 132.4146,\n        134.1711, 126.0395, 118.2248, 148.2446]) Cost: 1465.219360\nEpoch    4/20 Hypothesis: tensor([130.6657, 160.3159, 156.2713, 169.9530, 123.3339,  91.0573, 126.0321,\n         91.6543, 150.3529, 139.1062, 122.6462, 122.3192, 161.7224, 135.0189,\n        127.0826, 162.1665, 129.8936, 150.2901, 153.7145, 137.1674, 148.2992,\n        149.9911, 141.1841, 132.3692, 165.7206]) Cost: 551.693909\nEpoch    5/20 Hypothesis: tensor([139.1967, 170.5691, 166.3740, 180.9561, 131.1532,  96.8230, 134.2691,\n         97.7619, 159.9359, 147.9835, 130.5816, 130.1438, 172.1594, 143.6943,\n        135.3576, 172.5717, 138.1552, 160.1758, 163.6646, 146.0705, 157.9583,\n        159.6105, 150.3931, 140.9692, 176.3467]) Cost: 213.934662\nEpoch    6/20 Hypothesis: tensor([144.3838, 176.8035, 172.5169, 187.6467, 135.9075, 100.3289, 139.2780,\n        101.4764, 165.7629, 153.3819, 135.4068, 134.9018, 178.5053, 148.9688,\n        140.3896, 178.8986, 143.1777, 166.1873, 169.7144, 151.4838, 163.8318,\n        165.4597, 155.9930, 146.1978, 182.8077]) Cost: 89.052254\nEpoch    7/20 Hypothesis: tensor([147.5378, 180.5942, 176.2519, 191.7150, 138.7980, 102.4608, 142.3241,\n        103.7357, 169.3062, 156.6650, 138.3410, 137.7950, 182.3636, 152.1754,\n        143.4497, 182.7458, 146.2309, 169.8433, 173.3927, 154.7751, 167.4036,\n        169.0164, 159.3982, 149.3766, 186.7361]) Cost: 42.876022\nEpoch    8/20 Hypothesis: tensor([149.4556, 182.8990, 178.5229, 194.1888, 140.5553, 103.7572, 144.1767,\n        105.1102, 171.4608, 158.6619, 140.1253, 139.5545, 184.7093, 154.1246,\n        145.3108, 185.0851, 148.0866, 172.0669, 175.6289, 156.7761, 169.5758,\n        171.1792, 161.4691, 151.3089, 189.1245]) Cost: 25.799620\nEpoch    9/20 Hypothesis: tensor([150.6216, 184.3003, 179.9037, 195.6931, 141.6236, 104.5455, 145.3035,\n        105.9468, 172.7711, 159.8766, 141.2103, 140.6245, 186.1352, 155.3092,\n        146.4428, 186.5076, 149.2141, 173.4196, 176.9883, 157.9925, 170.8970,\n        172.4943, 162.7286, 152.4832, 190.5766]) Cost: 19.482409\nEpoch   10/20 Hypothesis: tensor([151.3305, 185.1522, 180.7431, 196.6078, 142.2728, 105.0250, 145.9890,\n        106.4561, 173.5679, 160.6158, 141.8702, 141.2753, 187.0020, 156.0289,\n        147.1316, 187.3727, 149.8989, 174.2426, 177.8145, 158.7319, 171.7007,\n        173.2940, 163.4948, 153.1967, 191.4593]) Cost: 17.143106\nEpoch   11/20 Hypothesis: tensor([151.7615, 185.6701, 181.2534, 197.1641, 142.6673, 105.3166, 146.4063,\n        106.7666, 174.0525, 161.0658, 142.2716, 141.6713, 187.5286, 156.4660,\n        147.5508, 187.8987, 150.3144, 174.7437, 178.3166, 159.1812, 172.1898,\n        173.7804, 163.9609, 153.6300, 191.9958]) Cost: 16.274515\nEpoch   12/20 Hypothesis: tensor([152.0235, 185.9849, 181.5636, 197.5024, 142.9069, 105.4941, 146.6604,\n        106.9561, 174.3473, 161.3400, 142.5158, 141.9122, 187.8485, 156.7312,\n        147.8060, 188.2186, 150.5663, 175.0490, 178.6215, 159.4542, 172.4875,\n        174.0762, 164.2446, 153.8929, 192.3217]) Cost: 15.949698\nEpoch   13/20 Hypothesis: tensor([152.1828, 186.1761, 181.7521, 197.7082, 143.0523, 105.6021, 146.8152,\n        107.0721, 174.5266, 161.5073, 142.6644, 142.0589, 188.0427, 156.8918,\n        147.9616, 188.4132, 150.7186, 175.2352, 178.8065, 159.6198, 172.6689,\n        174.2561, 164.4174, 154.0522, 192.5197]) Cost: 15.825971\nEpoch   14/20 Hypothesis: tensor([152.2795, 186.2923, 181.8665, 197.8334, 143.1404, 105.6678, 146.9098,\n        107.1433, 174.6358, 161.6096, 142.7549, 142.1483, 188.1604, 156.9889,\n        148.0567, 188.5316, 150.8104, 175.3491, 178.9187, 159.7203, 172.7795,\n        174.3657, 164.5228, 154.1485, 192.6399]) Cost: 15.776586\nEpoch   15/20 Hypothesis: tensor([152.3383, 186.3628, 181.9360, 197.9096, 143.1937, 105.7079, 146.9676,\n        107.1874, 174.7023, 161.6723, 142.8101, 142.2028, 188.2317, 157.0474,\n        148.1148, 188.6036, 150.8654, 175.4189, 178.9865, 159.7812, 172.8472,\n        174.4323, 164.5872, 154.2065, 192.7127]) Cost: 15.754648\nEpoch   16/20 Hypothesis: tensor([152.3739, 186.4055, 181.9781, 197.9560, 143.2258, 105.7324, 147.0032,\n        107.2149, 174.7428, 161.7110, 142.8438, 142.2361, 188.2747, 157.0823,\n        148.1506, 188.6475, 150.8980, 175.4619, 179.0275, 159.8179, 172.8887,\n        174.4729, 164.6266, 154.2411, 192.7567]) Cost: 15.742906\nEpoch   17/20 Hypothesis: tensor([152.3956, 186.4313, 182.0036, 197.9843, 143.2451, 105.7474, 147.0252,\n        107.2324, 174.7675, 161.7351, 142.8644, 142.2566, 188.3004, 157.1030,\n        148.1727, 188.6743, 150.9170, 175.4887, 179.0520, 159.8399, 172.9143,\n        174.4977, 164.6508, 154.2617, 192.7833]) Cost: 15.734898\nEpoch   18/20 Hypothesis: tensor([152.4086, 186.4469, 182.0190, 198.0016, 143.2565, 105.7566, 147.0389,\n        107.2437, 174.7827, 161.7503, 142.8770, 142.2692, 188.3158, 157.1150,\n        148.1866, 188.6906, 150.9277, 175.5055, 179.0666, 159.8531, 172.9302,\n        174.5128, 164.6659, 154.2736, 192.7992]) Cost: 15.728318\nEpoch   19/20 Hypothesis: tensor([152.4165, 186.4562, 182.0282, 198.0122, 143.2631, 105.7623, 147.0477,\n        107.2514, 174.7921, 161.7601, 142.8849, 142.2771, 188.3248, 157.1217,\n        148.1954, 188.7006, 150.9334, 175.5164, 179.0751, 159.8608, 172.9402,\n        174.5221, 164.6753, 154.2803, 192.8087]) Cost: 15.722224\nEpoch   20/20 Hypothesis: tensor([152.4212, 186.4618, 182.0337, 198.0186, 143.2669, 105.7658, 147.0534,\n        107.2567, 174.7978, 161.7666, 142.8898, 142.2821, 188.3299, 157.1252,\n        148.2011, 188.7067, 150.9361, 175.5236, 179.0799, 159.8652, 172.9467,\n        174.5278, 164.6814, 154.2838, 192.8142]) Cost: 15.716328\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)\n",
    "\n",
    "model = MultivariateLinearRegressionModel()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "\n",
    "nb_epochs = 20\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    #Hypothesis\n",
    "    pred = model(x_train)\n",
    "\n",
    "    #cost\n",
    "    cost = F.mse_loss(pred, y_train)\n",
    "\n",
    "    #Reduce Cost\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {:4d}/{} Hypothesis: {} Cost: {:.6f}'.format(epoch, nb_epochs, pred.squeeze().detach(), cost.item()))"
   ]
  },
  {
   "source": [
    "## Dataset and DataLoader"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}