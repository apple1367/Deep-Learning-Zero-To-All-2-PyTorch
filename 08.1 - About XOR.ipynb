{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lab 8-1: About XOR\r\n",
    "\r\n",
    "Edited By Steve Ive\r\n",
    "\r\n",
    "Reference From\r\n",
    "\r\n",
    "https://github.com/deeplearningzerotoall/PyTorch/blob/master/lab-08_1_xor.ipynb\r\n",
    "\r\n",
    "Here, the 'About XOR' will gonna handle about the XOR problem, that is proved \"1 Layer\" perceptron cannot solve the problem. We are gonna define the XOR Problem as a torch.tensor, and will create the 1 linear layer(~=1 layer perceptron) to sure about whether really the 1 layer perceptron cannot solve the problem."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "\r\n",
    "torch.manual_seed(1)\r\n",
    "if device == 'cuda':\r\n",
    "    torch.cuda.manual_seed_all(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the XOR Problem"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\r\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create 1 Layer Perceptron Model to solve the XOR."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#nn layers\r\n",
    "linear = torch.nn.Linear(2, 1)\r\n",
    "sigmoid = torch.nn.Sigmoid()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#model\r\n",
    "model = torch.nn.Sequential(linear, sigmoid).to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#Define cost & optimizer\r\n",
    "criterion = torch.nn.BCELoss().to(device)\r\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the 1-Layer Perceptron"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "for step in range(10001):\r\n",
    "    #prediction\r\n",
    "    pred = model(X)\r\n",
    "\r\n",
    "    #cost\r\n",
    "    cost = criterion(pred, Y)\r\n",
    "\r\n",
    "    #Reduce cost\r\n",
    "    optimizer.zero_grad()\r\n",
    "    cost.backward()\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    if step % 100 == 0:\r\n",
    "        result = torch.sigmoid(pred).squeeze().detach().cpu().numpy()\r\n",
    "        print('Epoch: {:2d}/1000 \\n Prediction: {} Cost: {:.6f}'.format(step, result, cost.item()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:  0/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 10000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Result\r\n",
    "\r\n",
    "As the results below, we can see the 1 layer perceptron(1 linear layer) **cannot solve the XOR problem.**(The maximum accruacy is 0.5, this means no matter how hard train it, it can only correct the half. - the property of the linear)\r\n",
    "\r\n",
    "This means that the 1 layer perceptron cannot solve the ***non-linear** problem, that can only solve the ***Linear*** Problem.\r\n",
    "\r\n",
    "![](https://miro.medium.com/max/962/1*YzgdEbLiB17x3jB28gSAdw.png)\r\n",
    "\r\n",
    "https://towardsdatascience.com/the-magic-behind-the-perceptron-network-eaa461088367"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "#Accuracy computation\r\n",
    "# True if hypothesis > 0.5 else False\r\n",
    "with torch.no_grad():\r\n",
    "    pred = model(X)\r\n",
    "    predicted = (pred > 0.5).float()\r\n",
    "    accuracy = (predicted == Y).float().mean()\r\n",
    "    print('\\n Hypothesis: ', pred.detach().cpu().numpy(), '\\n Correct: ', predicted.detach().cpu().numpy(), '\\n Accuracy: ', accuracy.item())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " Hypothesis:  [[0.500107  ]\n",
      " [0.49997312]\n",
      " [0.5000269 ]\n",
      " [0.49989298]] \n",
      " Correct:  [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]] \n",
      " Accuracy:  0.5\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('buddhalight': conda)"
  },
  "interpreter": {
   "hash": "38ed4d61829b01de31b0fe0651719916120d9f7e023a62cbbfea93b7d24a50a0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}